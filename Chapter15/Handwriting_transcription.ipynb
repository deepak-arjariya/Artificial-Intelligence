{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwriting_transcription.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepak-arjariya/Artificial-Intelligence/blob/main/Chapter15/Handwriting_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQDnOljOkTLT",
        "outputId": "5bce236a-8c47-4fac-e800-0ce800eec46e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/l2ul3upj7dkv4ou/synthetic-data.zip\n",
        "!unzip -qq synthetic-data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-29 06:09:55--  https://www.dropbox.com/s/l2ul3upj7dkv4ou/synthetic-data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6020:18::a27d:4012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/h1ah6l3kcg2ftkzs3x7zq/synthetic-data.zip?rlkey=p5neobjb686znulll16rgxdx9 [following]\n",
            "--2025-03-29 06:09:55--  https://www.dropbox.com/scl/fi/h1ah6l3kcg2ftkzs3x7zq/synthetic-data.zip?rlkey=p5neobjb686znulll16rgxdx9\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc37c93d674485201ac764278bae.dl.dropboxusercontent.com/cd/0/inline/Cmzdm4PSMxioCa5pYncrdKn2T7rofz8GNVHZOaHy0kMotZbaIyy4puwScJH7LNLncVgki7iJ5JhTGShKYwZZCrNsrMH9WkLZbzFwDTNXg1GNeKwvbr3dmjtXtp8oNziNk6Q6Gcc_M6OtnKXWuWSrSO5S/file# [following]\n",
            "--2025-03-29 06:09:56--  https://uc37c93d674485201ac764278bae.dl.dropboxusercontent.com/cd/0/inline/Cmzdm4PSMxioCa5pYncrdKn2T7rofz8GNVHZOaHy0kMotZbaIyy4puwScJH7LNLncVgki7iJ5JhTGShKYwZZCrNsrMH9WkLZbzFwDTNXg1GNeKwvbr3dmjtXtp8oNziNk6Q6Gcc_M6OtnKXWuWSrSO5S/file\n",
            "Resolving uc37c93d674485201ac764278bae.dl.dropboxusercontent.com (uc37c93d674485201ac764278bae.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to uc37c93d674485201ac764278bae.dl.dropboxusercontent.com (uc37c93d674485201ac764278bae.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CmwRy6_nILxyeEBDnhiDIlmF76sO_lRbu4CEnF3PZlnHEPMI5372Xb1MsLFwxa89JZwSEC3GCqi2iKL-T051eeTGXoKXI24AU2FQnQx-fDZrdohOAJWMut7am3yGFhdAbMmDm9Njdd93GZEYf4RZY2r-AydVFqV9SlB2YwAKQ9ql9QuOGjkXfQFJFwjYpX1aVDffxkuTmGuyJE--1nd_hnCqp_pFG9iKb_n3T4aINS-6l7dOUy6rapU60sO7sTXzKV5oinEyVbTQPui-yGBRQt-rIKVA9mYOe0L2bpAqRZ0sNgk2U3IeurYg059wJKazmIVH6mErrOnu9ObkrVnAhrE19Fijd8QEY5_Ewyois-ChBIC0vto5MtP1AEAuP_x2OEg/file [following]\n",
            "--2025-03-29 06:09:57--  https://uc37c93d674485201ac764278bae.dl.dropboxusercontent.com/cd/0/inline2/CmwRy6_nILxyeEBDnhiDIlmF76sO_lRbu4CEnF3PZlnHEPMI5372Xb1MsLFwxa89JZwSEC3GCqi2iKL-T051eeTGXoKXI24AU2FQnQx-fDZrdohOAJWMut7am3yGFhdAbMmDm9Njdd93GZEYf4RZY2r-AydVFqV9SlB2YwAKQ9ql9QuOGjkXfQFJFwjYpX1aVDffxkuTmGuyJE--1nd_hnCqp_pFG9iKb_n3T4aINS-6l7dOUy6rapU60sO7sTXzKV5oinEyVbTQPui-yGBRQt-rIKVA9mYOe0L2bpAqRZ0sNgk2U3IeurYg059wJKazmIVH6mErrOnu9ObkrVnAhrE19Fijd8QEY5_Ewyois-ChBIC0vto5MtP1AEAuP_x2OEg/file\n",
            "Reusing existing connection to uc37c93d674485201ac764278bae.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39876999 (38M) [application/zip]\n",
            "Saving to: ‘synthetic-data.zip.1’\n",
            "\n",
            "synthetic-data.zip. 100%[===================>]  38.03M  22.6MB/s    in 1.7s    \n",
            "\n",
            "2025-03-29 06:09:59 (22.6 MB/s) - ‘synthetic-data.zip.1’ saved [39876999/39876999]\n",
            "\n",
            "replace synthetic-data/picture@0JjYnP.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqAz_bnxkV6w",
        "outputId": "b024fe17-4ec5-4a5e-b616-da73a13897c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch_snippets torch_summary editdistance"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_snippets\n",
            "  Downloading torch_snippets-0.553-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting torch_summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (1.7.29)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (11.1.0)\n",
            "Collecting dill (from torch_snippets)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting loguru (from torch_snippets)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (13.9.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (6.0.2)\n",
            "Requirement already satisfied: catalogue in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.0.10)\n",
            "Requirement already satisfied: confection in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (0.1.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.10.6)\n",
            "Collecting typing (from torch_snippets)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (4.12.2)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (1.1.3)\n",
            "Collecting jsonlines (from torch_snippets)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting imgaug>=0.4.0 (from torch_snippets)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xmltodict (from torch_snippets)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting fuzzywuzzy (from torch_snippets)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (3.9.1)\n",
            "Collecting python-Levenshtein (from torch_snippets)\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pre-commit (from torch_snippets)\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting icecream (from torch_snippets)\n",
            "  Downloading icecream-2.1.4-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting mergedeep (from torch_snippets)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting deepdiff (from torch_snippets)\n",
            "  Downloading deepdiff-8.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (0.15.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (1.14.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (4.11.0.86)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (2.37.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->torch_snippets) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->torch_snippets) (2.27.2)\n",
            "Collecting orderly-set<6,>=5.3.0 (from deepdiff->torch_snippets)\n",
            "  Downloading orderly_set-5.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastcore->torch_snippets) (24.2)\n",
            "Collecting colorama>=0.3.9 (from icecream->torch_snippets)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from icecream->torch_snippets) (2.18.0)\n",
            "Collecting executing>=2.1.0 (from icecream->torch_snippets)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream->torch_snippets)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->torch_snippets) (25.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->torch_snippets) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->torch_snippets) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->torch_snippets) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->torch_snippets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->torch_snippets) (2025.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->torch_snippets)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->torch_snippets)\n",
            "  Downloading identify-2.6.9-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->torch_snippets)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->torch_snippets)\n",
            "  Downloading virtualenv-20.29.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein->torch_snippets)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein->torch_snippets)\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->torch_snippets) (3.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->torch_snippets) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->torch_snippets) (0.1.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch_snippets) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch_snippets) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch_snippets) (0.4)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->torch_snippets)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->torch_snippets) (3.18.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->torch_snippets) (4.3.7)\n",
            "Downloading torch_snippets-0.553-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.4.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading icecream-2.1.4-py3-none-any.whl (14 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading identify-2.6.9-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading orderly_set-5.3.0-py3-none-any.whl (12 kB)\n",
            "Downloading virtualenv-20.29.3-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26303 sha256=f97d1d7e49c2c09350d453c1bf67f0224c8a3b9325549d95859b97b71cfd8edc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "Successfully built typing\n",
            "Installing collected packages: fuzzywuzzy, distlib, xmltodict, virtualenv, typing, torch_summary, rapidfuzz, orderly-set, nodeenv, mergedeep, loguru, jsonlines, identify, executing, dill, colorama, cfgv, asttokens, pre-commit, Levenshtein, icecream, deepdiff, python-Levenshtein, imgaug, torch_snippets\n",
            "Successfully installed Levenshtein-0.27.1 asttokens-3.0.0 cfgv-3.4.0 colorama-0.4.6 deepdiff-8.4.2 dill-0.3.9 distlib-0.3.9 executing-2.2.0 fuzzywuzzy-0.18.0 icecream-2.1.4 identify-2.6.9 imgaug-0.4.0 jsonlines-4.0.0 loguru-0.7.3 mergedeep-1.3.4 nodeenv-1.9.1 orderly-set-5.3.0 pre-commit-4.2.0 python-Levenshtein-0.27.1 rapidfuzz-3.12.2 torch_snippets-0.553 torch_summary-1.4.5 typing-3.7.4.3 virtualenv-20.29.3 xmltodict-0.14.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "5a1294325aeb4171a1e6daca177c0f5e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1IOQ7q9kX6Y"
      },
      "source": [
        "from torch_snippets import *\n",
        "from torchsummary import summary\n",
        "import editdistance"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sT64jwokZJ1"
      },
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "fname2label = lambda fname: stem(fname).split('@')[0]\n",
        "images = Glob('synthetic-data')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N0yxeI8kafV"
      },
      "source": [
        "vocab = 'QWERTYUIOPASDFGHJKLZXCVBNMqwertyuiopasdfghjklzxcvbnm'\n",
        "B,T,V = 64, 32, len(vocab)\n",
        "H,W = 32, 128"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ImW_I4kb3Z"
      },
      "source": [
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, items, vocab=vocab, preprocess_shape=(H,W), timesteps=T):\n",
        "        super().__init__()\n",
        "        self.items = items\n",
        "        self.charList = {ix+1:ch for ix,ch in enumerate(vocab)}\n",
        "        self.charList.update({0: '`'})\n",
        "        self.invCharList = {v:k for k,v in self.charList.items()}\n",
        "        self.ts = timesteps\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "    def sample(self):\n",
        "        return self[randint(len(self))]\n",
        "    def __getitem__(self, ix):\n",
        "        item = self.items[ix]\n",
        "        image = cv2.imread(item, 0)\n",
        "        label = fname2label(item)\n",
        "        return image, label\n",
        "    def collate_fn(self, batch):\n",
        "        images, labels, label_lengths, label_vectors, input_lengths = [], [], [], [], []\n",
        "        for image, label in batch:\n",
        "            images.append(torch.Tensor(self.preprocess(image))[None,None])\n",
        "            label_lengths.append(len(label))\n",
        "            labels.append(label)\n",
        "            label_vectors.append(self.str2vec(label))\n",
        "            input_lengths.append(self.ts)\n",
        "        images = torch.cat(images).float().to(device)\n",
        "        label_lengths = torch.Tensor(label_lengths).long().to(device)\n",
        "        label_vectors = torch.Tensor(label_vectors).long().to(device)\n",
        "        input_lengths = torch.Tensor(input_lengths).long().to(device)\n",
        "        return images, label_vectors, label_lengths, input_lengths, labels\n",
        "    def str2vec(self, string, pad=True):\n",
        "        string = ''.join([s for s in string if s in self.invCharList])\n",
        "        val = list(map(lambda x: self.invCharList[x], string))\n",
        "        if pad:\n",
        "            while len(val) < self.ts:\n",
        "                val.append(0)\n",
        "        return val\n",
        "    def preprocess(self, img, shape=(32,128)):\n",
        "        target = np.ones(shape)*255\n",
        "        try:\n",
        "            H, W = shape\n",
        "            h, w = img.shape\n",
        "            fx = H/h\n",
        "            fy = W/w\n",
        "            f = min(fx, fy)\n",
        "            _h = int(h*f)\n",
        "            _w = int(w*f)\n",
        "            _img = cv2.resize(img, (_w,_h))\n",
        "            target[:_h,:_w] = _img\n",
        "        except:\n",
        "            ...\n",
        "        return (255-target)/255\n",
        "    def decoder_chars(self, pred):\n",
        "        decoded = \"\"\n",
        "        last = \"\"\n",
        "        pred = pred.cpu().detach().numpy()\n",
        "        for i in range(len(pred)):\n",
        "            k = np.argmax(pred[i])\n",
        "            if k > 0 and self.charList[k] != last:\n",
        "                last = self.charList[k]\n",
        "                decoded = decoded + last\n",
        "            elif k > 0 and self.charList[k] == last:\n",
        "                continue\n",
        "            else:\n",
        "                last = \"\"\n",
        "        return decoded.replace(\" \",\" \")\n",
        "    def wer(self, preds, labels):\n",
        "        c = 0\n",
        "        for p, l in zip(preds, labels):\n",
        "            c += p.lower().strip() != l.lower().strip()\n",
        "        return round(c/len(preds), 4)\n",
        "    def cer(self, preds, labels):\n",
        "        c, d = [], []\n",
        "        for p, l in zip(preds, labels):\n",
        "            c.append(editdistance.eval(p, l) / len(l))\n",
        "        return round(np.mean(c), 4)\n",
        "    def evaluate(self, model, ims, labels, lower=False):\n",
        "        model.eval()\n",
        "        preds = model(ims).permute(1,0,2) # B, T, V+1\n",
        "        preds = [self.decoder_chars(pred) for pred in preds]\n",
        "        return {'char-error-rate': self.cer(preds, labels),\n",
        "                'word-error-rate': self.wer(preds, labels),\n",
        "                'char-accuracy' : 1 - self.cer(preds, labels),\n",
        "                'word-accuracy' : 1 - self.wer(preds, labels)}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1zYLnvmke6-",
        "outputId": "e1e9c4a9-8aed-4857-edf2-02f26622a45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trn_items, val_items = train_test_split(Glob('synthetic-data'), test_size=0.2, random_state=22)\n",
        "trn_ds = OCRDataset(trn_items)\n",
        "val_ds = OCRDataset(val_items)\n",
        "\n",
        "trn_dl = DataLoader(trn_ds, batch_size=B, collate_fn=trn_ds.collate_fn, drop_last=True, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=B, collate_fn=val_ds.collate_fn, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-02 13:49:48.111 | INFO     | torch_snippets.loader:Glob:160 - 25132 files found at synthetic-data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywO4IMsZk2g1"
      },
      "source": [
        "from torch_snippets import Reshape, Permute\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, ni, no, ks=3, st=1, padding=1, pool=2, drop=0.2):\n",
        "        super().__init__()\n",
        "        self.ks = ks\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ni, no, kernel_size=ks, stride=st, padding=padding),\n",
        "            nn.BatchNorm2d(no, momentum=0.3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(pool),\n",
        "            nn.Dropout2d(drop)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3K_qrPek42x"
      },
      "source": [
        "class Ocr(nn.Module):\n",
        "    def __init__(self, vocab):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            BasicBlock( 1, 128),\n",
        "            BasicBlock(128, 128),\n",
        "            BasicBlock(128, 256, pool=(4,2)),\n",
        "            Reshape(-1, 256, 32),\n",
        "            Permute(2, 0, 1) # T, B, D\n",
        "        )\n",
        "        self.rnn = nn.Sequential(\n",
        "            nn.LSTM(256, 256, num_layers=2, dropout=0.2, bidirectional=True),\n",
        "        )\n",
        "        self.classification = nn.Sequential(\n",
        "            nn.Linear(512, vocab+1),\n",
        "            nn.LogSoftmax(-1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x, lstm_states = self.rnn(x)\n",
        "        y = self.classification(x)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oc3qXBRk7Fh"
      },
      "source": [
        "def ctc(log_probs, target, input_lengths, target_lengths, blank=0):\n",
        "    loss = nn.CTCLoss(blank=blank, zero_infinity=True)\n",
        "    ctc_loss = loss(log_probs, target, input_lengths, target_lengths)\n",
        "    return ctc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIsrWALYk-wh",
        "outputId": "8a328366-c12c-48d0-9d94-b7ea0f396ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "model = Ocr(len(vocab)).to(device)\n",
        "!pip install torch_summary\n",
        "from torchsummary import summary\n",
        "summary(model, torch.zeros((1,1,32,128)).to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_summary in /usr/local/lib/python3.6/dist-packages (1.4.3)\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Sequential: 1-1                        [-1, 1, 256]              --\n",
            "|    └─BasicBlock: 2-1                   [-1, 128, 16, 64]         --\n",
            "|    |    └─Sequential: 3-1              [-1, 128, 16, 64]         1,536\n",
            "|    └─BasicBlock: 2-2                   [-1, 128, 8, 32]          --\n",
            "|    |    └─Sequential: 3-2              [-1, 128, 8, 32]          147,840\n",
            "|    └─BasicBlock: 2-3                   [-1, 256, 2, 16]          --\n",
            "|    |    └─Sequential: 3-3              [-1, 256, 2, 16]          295,680\n",
            "|    └─Reshape: 2-4                      [-1, 256, 32]             --\n",
            "|    └─Permute: 2-5                      [-1, 1, 256]              --\n",
            "├─Sequential: 1-2                        [-1, 1, 512]              --\n",
            "|    └─LSTM: 2-6                         [-1, 1, 512]              2,629,632\n",
            "├─Sequential: 1-3                        [-1, 1, 53]               --\n",
            "|    └─Linear: 2-7                       [-1, 1, 53]               27,189\n",
            "|    └─LogSoftmax: 2-8                   [-1, 1, 53]               --\n",
            "==========================================================================================\n",
            "Total params: 3,101,877\n",
            "Trainable params: 3,101,877\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 237.84\n",
            "==========================================================================================\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 11.00\n",
            "Params size (MB): 11.83\n",
            "Estimated Total Size (MB): 22.85\n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 1, 256]              --\n",
              "|    └─BasicBlock: 2-1                   [-1, 128, 16, 64]         --\n",
              "|    |    └─Sequential: 3-1              [-1, 128, 16, 64]         1,536\n",
              "|    └─BasicBlock: 2-2                   [-1, 128, 8, 32]          --\n",
              "|    |    └─Sequential: 3-2              [-1, 128, 8, 32]          147,840\n",
              "|    └─BasicBlock: 2-3                   [-1, 256, 2, 16]          --\n",
              "|    |    └─Sequential: 3-3              [-1, 256, 2, 16]          295,680\n",
              "|    └─Reshape: 2-4                      [-1, 256, 32]             --\n",
              "|    └─Permute: 2-5                      [-1, 1, 256]              --\n",
              "├─Sequential: 1-2                        [-1, 1, 512]              --\n",
              "|    └─LSTM: 2-6                         [-1, 1, 512]              2,629,632\n",
              "├─Sequential: 1-3                        [-1, 1, 53]               --\n",
              "|    └─Linear: 2-7                       [-1, 1, 53]               27,189\n",
              "|    └─LogSoftmax: 2-8                   [-1, 1, 53]               --\n",
              "==========================================================================================\n",
              "Total params: 3,101,877\n",
              "Trainable params: 3,101,877\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 237.84\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 11.00\n",
              "Params size (MB): 11.83\n",
              "Estimated Total Size (MB): 22.85\n",
              "=========================================================================================="
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs7CY0BYlAn1"
      },
      "source": [
        "def train_batch(data, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    imgs, targets, label_lens, input_lens, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(imgs)\n",
        "    loss = criterion(preds, targets, input_lens, label_lens)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    results = trn_ds.evaluate(model, imgs.to(device), labels)\n",
        "    return loss, results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpyuNswnlmSC"
      },
      "source": [
        "@torch.no_grad()\n",
        "def validate_batch(data, model):\n",
        "    model.eval()\n",
        "    imgs, targets, label_lens, input_lens, labels = data\n",
        "    preds = model(imgs)\n",
        "    loss = criterion(preds, targets, input_lens, label_lens)\n",
        "    return loss, val_ds.evaluate(model, imgs.to(device), labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzGBIQ-qloEB"
      },
      "source": [
        "model = Ocr(len(vocab)).to(device)\n",
        "criterion = ctc\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-3)\n",
        "\n",
        "n_epochs = 50\n",
        "log = Report(n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zmJcfsklpl8",
        "outputId": "306fd2be-6265-448b-8a59-1e35382fae17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for ep in range( n_epochs):\n",
        "    # if ep in lr_schedule: optimizer = AdamW(ocr.parameters(), lr=lr_schedule[ep])\n",
        "    N = len(trn_dl)\n",
        "    for ix, data in enumerate(trn_dl):\n",
        "        pos = ep + (ix+1)/N\n",
        "        loss, results = train_batch(data, model, optimizer, criterion)\n",
        "        # scheduler.step()\n",
        "        ca, wa = results['char-accuracy'], results['word-accuracy']\n",
        "        log.record(pos=pos, trn_loss=loss, trn_char_acc=ca, trn_word_acc=wa, end='\\r')\n",
        "    val_results = []\n",
        "    N = len(val_dl)\n",
        "    for ix, data in enumerate(val_dl):\n",
        "        pos = ep + (ix+1)/N\n",
        "        loss, results = validate_batch(data, model)\n",
        "        ca, wa = results['char-accuracy'], results['word-accuracy']\n",
        "        log.record(pos=pos, val_loss=loss, val_char_acc=ca, val_word_acc=wa, end='\\r')\n",
        "\n",
        "    log.report_avgs(ep+1)\n",
        "    print()\n",
        "    for jx in range(5):\n",
        "        img, label = val_ds.sample()\n",
        "        _img = torch.Tensor(val_ds.preprocess(img)[None,None]).to(device)\n",
        "        pred = model(_img)[:,0,:]\n",
        "        pred = trn_ds.decoder_chars(pred)\n",
        "        print(f'Pred: `{pred}` :: Truth: `{label}`')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 1.000\ttrn_loss: 3.327\ttrn_char_acc: 0.012\ttrn_word_acc: 0.000\tval_loss: 3.033\tval_char_acc: 0.053\tval_word_acc: 0.000\t(56.00s - 2744.13s remaining)\n",
            "\n",
            "Pred: `b` :: Truth: `finish`\n",
            "Pred: `s` :: Truth: `attack`\n",
            "Pred: `b` :: Truth: `beautiful`\n",
            "Pred: `m` :: Truth: `represent`\n",
            "Pred: `m` :: Truth: `what`\n",
            "\n",
            "EPOCH: 2.000\ttrn_loss: 2.633\ttrn_char_acc: 0.214\ttrn_word_acc: 0.005\tval_loss: 1.957\tval_char_acc: 0.423\tval_word_acc: 0.031\t(87.98s - 2111.44s remaining)\n",
            "\n",
            "Pred: `huaa` :: Truth: `know`\n",
            "Pred: `mrd` :: Truth: `really`\n",
            "Pred: `sentrer` :: Truth: `control`\n",
            "Pred: `wet` :: Truth: `west`\n",
            "Pred: `pareene` :: Truth: `someone`\n",
            "\n",
            "EPOCH: 3.000\ttrn_loss: 1.615\ttrn_char_acc: 0.590\ttrn_word_acc: 0.124\tval_loss: 1.164\tval_char_acc: 0.667\tval_word_acc: 0.204\t(119.94s - 1879.07s remaining)\n",
            "\n",
            "Pred: `theony` :: Truth: `theory`\n",
            "Pred: `t` :: Truth: `I`\n",
            "Pred: `whin` :: Truth: `worker`\n",
            "Pred: `liod` :: Truth: `word`\n",
            "Pred: `dinectod` :: Truth: `director`\n",
            "\n",
            "EPOCH: 4.000\ttrn_loss: 1.095\ttrn_char_acc: 0.747\ttrn_word_acc: 0.314\tval_loss: 0.801\tval_char_acc: 0.777\tval_word_acc: 0.371\t(151.87s - 1746.51s remaining)\n",
            "\n",
            "Pred: `evening` :: Truth: `evening`\n",
            "Pred: `plauer` :: Truth: `player`\n",
            "Pred: `wide` :: Truth: `wide`\n",
            "Pred: `shale` :: Truth: `shake`\n",
            "Pred: `forocess` :: Truth: `process`\n",
            "\n",
            "EPOCH: 5.000\ttrn_loss: 0.832\ttrn_char_acc: 0.826\ttrn_word_acc: 0.469\tval_loss: 0.616\tval_char_acc: 0.830\tval_word_acc: 0.492\t(183.95s - 1655.54s remaining)\n",
            "\n",
            "Pred: `raise` :: Truth: `raise`\n",
            "Pred: `commercial` :: Truth: `commercial`\n",
            "Pred: `note` :: Truth: `note`\n",
            "Pred: `bring` :: Truth: `bring`\n",
            "Pred: `assume` :: Truth: `assume`\n",
            "\n",
            "EPOCH: 6.000\ttrn_loss: 0.656\ttrn_char_acc: 0.874\ttrn_word_acc: 0.580\tval_loss: 0.499\tval_char_acc: 0.864\tval_word_acc: 0.571\t(216.05s - 1584.37s remaining)\n",
            "\n",
            "Pred: `nlion` :: Truth: `million`\n",
            "Pred: `actiuity` :: Truth: `activity`\n",
            "Pred: `imgine` :: Truth: `imagine`\n",
            "Pred: `tax` :: Truth: `tax`\n",
            "Pred: `dshernt` :: Truth: `different`\n",
            "\n",
            "EPOCH: 7.000\ttrn_loss: 0.531\ttrn_char_acc: 0.906\ttrn_word_acc: 0.671\tval_loss: 0.428\tval_char_acc: 0.880\tval_word_acc: 0.605\t(248.11s - 1524.09s remaining)\n",
            "\n",
            "Pred: `region` :: Truth: `region`\n",
            "Pred: `to` :: Truth: `to`\n",
            "Pred: `senvice` :: Truth: `service`\n",
            "Pred: `individual` :: Truth: `individual`\n",
            "Pred: `activity` :: Truth: `activity`\n",
            "\n",
            "EPOCH: 8.000\ttrn_loss: 0.439\ttrn_char_acc: 0.926\ttrn_word_acc: 0.729\tval_loss: 0.359\tval_char_acc: 0.900\tval_word_acc: 0.665\t(280.34s - 1471.77s remaining)\n",
            "\n",
            "Pred: `berubucan` :: Truth: `Republican`\n",
            "Pred: `inpotaut` :: Truth: `important`\n",
            "Pred: `suggest` :: Truth: `suggest`\n",
            "Pred: `TV` :: Truth: `TV`\n",
            "Pred: `not` :: Truth: `not`\n",
            "\n",
            "EPOCH: 9.000\ttrn_loss: 0.375\ttrn_char_acc: 0.942\ttrn_word_acc: 0.778\tval_loss: 0.318\tval_char_acc: 0.910\tval_word_acc: 0.692\t(312.57s - 1423.91s remaining)\n",
            "\n",
            "Pred: `political` :: Truth: `political`\n",
            "Pred: `thue` :: Truth: `thus`\n",
            "Pred: `allo` :: Truth: `allow`\n",
            "Pred: `experaly` :: Truth: `especially`\n",
            "Pred: `admit` :: Truth: `admit`\n",
            "\n",
            "EPOCH: 10.000\ttrn_loss: 0.325\ttrn_char_acc: 0.952\ttrn_word_acc: 0.812\tval_loss: 0.291\tval_char_acc: 0.920\tval_word_acc: 0.720\t(344.94s - 1379.75s remaining)\n",
            "\n",
            "Pred: `choam` :: Truth: `clear`\n",
            "Pred: `just` :: Truth: `just`\n",
            "Pred: `southern` :: Truth: `southern`\n",
            "Pred: `add` :: Truth: `add`\n",
            "Pred: `family` :: Truth: `family`\n",
            "\n",
            "EPOCH: 11.000\ttrn_loss: 0.282\ttrn_char_acc: 0.961\ttrn_word_acc: 0.844\tval_loss: 0.278\tval_char_acc: 0.923\tval_word_acc: 0.732\t(377.24s - 1337.47s remaining)\n",
            "\n",
            "Pred: `green` :: Truth: `green`\n",
            "Pred: `check` :: Truth: `check`\n",
            "Pred: `proride` :: Truth: `provide`\n",
            "Pred: `expert` :: Truth: `expert`\n",
            "Pred: `leter` :: Truth: `letter`\n",
            "\n",
            "EPOCH: 12.000\ttrn_loss: 0.249\ttrn_char_acc: 0.967\ttrn_word_acc: 0.863\tval_loss: 0.244\tval_char_acc: 0.931\tval_word_acc: 0.762\t(409.68s - 1297.32s remaining)\n",
            "\n",
            "Pred: `particwlarly` :: Truth: `particularly`\n",
            "Pred: `watch` :: Truth: `watch`\n",
            "Pred: `try` :: Truth: `try`\n",
            "Pred: `now` :: Truth: `now`\n",
            "Pred: `tatal` :: Truth: `total`\n",
            "\n",
            "EPOCH: 13.000\ttrn_loss: 0.223\ttrn_char_acc: 0.972\ttrn_word_acc: 0.885\tval_loss: 0.234\tval_char_acc: 0.937\tval_word_acc: 0.779\t(441.96s - 1257.89s remaining)\n",
            "\n",
            "Pred: `improve` :: Truth: `improve`\n",
            "Pred: `require` :: Truth: `require`\n",
            "Pred: `from` :: Truth: `from`\n",
            "Pred: `various` :: Truth: `various`\n",
            "Pred: `high` :: Truth: `high`\n",
            "\n",
            "EPOCH: 14.000\ttrn_loss: 0.207\ttrn_char_acc: 0.976\ttrn_word_acc: 0.901\tval_loss: 0.216\tval_char_acc: 0.938\tval_word_acc: 0.791\t(474.01s - 1218.89s remaining)\n",
            "\n",
            "Pred: `wide` :: Truth: `wide`\n",
            "Pred: `clearly` :: Truth: `clearly`\n",
            "Pred: `reduce` :: Truth: `reduce`\n",
            "Pred: `hot` :: Truth: `hot`\n",
            "Pred: `into` :: Truth: `into`\n",
            "\n",
            "EPOCH: 15.000\ttrn_loss: 0.184\ttrn_char_acc: 0.980\ttrn_word_acc: 0.911\tval_loss: 0.215\tval_char_acc: 0.941\tval_word_acc: 0.792\t(506.08s - 1180.84s remaining)\n",
            "\n",
            "Pred: `item` :: Truth: `item`\n",
            "Pred: `bank` :: Truth: `bank`\n",
            "Pred: `decide` :: Truth: `decide`\n",
            "Pred: `apainst` :: Truth: `against`\n",
            "Pred: `none` :: Truth: `none`\n",
            "\n",
            "EPOCH: 16.000\ttrn_loss: 0.165\ttrn_char_acc: 0.983\ttrn_word_acc: 0.924\tval_loss: 0.208\tval_char_acc: 0.944\tval_word_acc: 0.799\t(538.20s - 1143.68s remaining)\n",
            "\n",
            "Pred: `especially` :: Truth: `especially`\n",
            "Pred: `oder` :: Truth: `order`\n",
            "Pred: `main` :: Truth: `main`\n",
            "Pred: `husband` :: Truth: `husband`\n",
            "Pred: `power` :: Truth: `power`\n",
            "\n",
            "EPOCH: 17.000\ttrn_loss: 0.156\ttrn_char_acc: 0.985\ttrn_word_acc: 0.931\tval_loss: 0.198\tval_char_acc: 0.946\tval_word_acc: 0.812\t(570.16s - 1106.78s remaining)\n",
            "\n",
            "Pred: `us` :: Truth: `us`\n",
            "Pred: `program` :: Truth: `program`\n",
            "Pred: `case` :: Truth: `case`\n",
            "Pred: `change` :: Truth: `change`\n",
            "Pred: `customer` :: Truth: `customer`\n",
            "\n",
            "EPOCH: 18.000\ttrn_loss: 0.142\ttrn_char_acc: 0.987\ttrn_word_acc: 0.941\tval_loss: 0.192\tval_char_acc: 0.947\tval_word_acc: 0.815\t(602.21s - 1070.60s remaining)\n",
            "\n",
            "Pred: `father` :: Truth: `father`\n",
            "Pred: `bank` :: Truth: `bank`\n",
            "Pred: `property` :: Truth: `property`\n",
            "Pred: `respond` :: Truth: `respond`\n",
            "Pred: `reason` :: Truth: `reason`\n",
            "\n",
            "EPOCH: 19.000\ttrn_loss: 0.133\ttrn_char_acc: 0.988\ttrn_word_acc: 0.946\tval_loss: 0.195\tval_char_acc: 0.946\tval_word_acc: 0.816\t(634.27s - 1034.85s remaining)\n",
            "\n",
            "Pred: `middle` :: Truth: `middle`\n",
            "Pred: `heatt` :: Truth: `health`\n",
            "Pred: `finally` :: Truth: `finally`\n",
            "Pred: `artist` :: Truth: `artist`\n",
            "Pred: `bad` :: Truth: `bad`\n",
            "\n",
            "EPOCH: 20.000\ttrn_loss: 0.126\ttrn_char_acc: 0.990\ttrn_word_acc: 0.951\tval_loss: 0.182\tval_char_acc: 0.950\tval_word_acc: 0.827\t(666.38s - 999.57s remaining)\n",
            "\n",
            "Pred: `station` :: Truth: `station`\n",
            "Pred: `research` :: Truth: `research`\n",
            "Pred: `thing` :: Truth: `thing`\n",
            "Pred: `or` :: Truth: `or`\n",
            "Pred: `name` :: Truth: `name`\n",
            "\n",
            "EPOCH: 21.000\ttrn_loss: 0.120\ttrn_char_acc: 0.991\ttrn_word_acc: 0.957\tval_loss: 0.180\tval_char_acc: 0.950\tval_word_acc: 0.829\t(698.30s - 964.32s remaining)\n",
            "\n",
            "Pred: `woman` :: Truth: `woman`\n",
            "Pred: `run` :: Truth: `run`\n",
            "Pred: `many` :: Truth: `many`\n",
            "Pred: `another` :: Truth: `another`\n",
            "Pred: `reduce` :: Truth: `reduce`\n",
            "\n",
            "EPOCH: 22.000\ttrn_loss: 0.112\ttrn_char_acc: 0.992\ttrn_word_acc: 0.960\tval_loss: 0.195\tval_char_acc: 0.948\tval_word_acc: 0.816\t(730.23s - 929.39s remaining)\n",
            "\n",
            "Pred: `fear` :: Truth: `fear`\n",
            "Pred: `less` :: Truth: `less`\n",
            "Pred: `raise` :: Truth: `raise`\n",
            "Pred: `commercial` :: Truth: `commercial`\n",
            "Pred: `history` :: Truth: `history`\n",
            "\n",
            "EPOCH: 23.000\ttrn_loss: 0.106\ttrn_char_acc: 0.993\ttrn_word_acc: 0.965\tval_loss: 0.174\tval_char_acc: 0.953\tval_word_acc: 0.835\t(762.23s - 894.79s remaining)\n",
            "\n",
            "Pred: `decade` :: Truth: `decade`\n",
            "Pred: `occur` :: Truth: `occur`\n",
            "Pred: `worber` :: Truth: `worker`\n",
            "Pred: `south` :: Truth: `south`\n",
            "Pred: `bill` :: Truth: `bill`\n",
            "\n",
            "EPOCH: 24.000\ttrn_loss: 0.098\ttrn_char_acc: 0.994\ttrn_word_acc: 0.969\tval_loss: 0.193\tval_char_acc: 0.951\tval_word_acc: 0.828\t(794.16s - 860.34s remaining)\n",
            "\n",
            "Pred: `force` :: Truth: `force`\n",
            "Pred: `alone` :: Truth: `alone`\n",
            "Pred: `significant` :: Truth: `significant`\n",
            "Pred: `posible` :: Truth: `possible`\n",
            "Pred: `woman` :: Truth: `woman`\n",
            "\n",
            "EPOCH: 25.000\ttrn_loss: 0.097\ttrn_char_acc: 0.994\ttrn_word_acc: 0.971\tval_loss: 0.194\tval_char_acc: 0.951\tval_word_acc: 0.823\t(826.14s - 826.14s remaining)\n",
            "\n",
            "Pred: `deep` :: Truth: `deep`\n",
            "Pred: `table` :: Truth: `table`\n",
            "Pred: `across` :: Truth: `across`\n",
            "Pred: `production` :: Truth: `production`\n",
            "Pred: `ife` :: Truth: `life`\n",
            "\n",
            "EPOCH: 26.000\ttrn_loss: 0.087\ttrn_char_acc: 0.995\ttrn_word_acc: 0.975\tval_loss: 0.187\tval_char_acc: 0.953\tval_word_acc: 0.839\t(858.06s - 792.05s remaining)\n",
            "\n",
            "Pred: `sign` :: Truth: `sign`\n",
            "Pred: `local` :: Truth: `local`\n",
            "Pred: `nove` :: Truth: `move`\n",
            "Pred: `sense` :: Truth: `sense`\n",
            "Pred: `pesple` :: Truth: `people`\n",
            "\n",
            "EPOCH: 27.000\ttrn_loss: 0.087\ttrn_char_acc: 0.996\ttrn_word_acc: 0.976\tval_loss: 0.177\tval_char_acc: 0.955\tval_word_acc: 0.844\t(889.98s - 758.13s remaining)\n",
            "\n",
            "Pred: `than` :: Truth: `than`\n",
            "Pred: `reveal` :: Truth: `reveal`\n",
            "Pred: `culture` :: Truth: `culture`\n",
            "Pred: `neturk` :: Truth: `network`\n",
            "Pred: `could` :: Truth: `could`\n",
            "\n",
            "EPOCH: 28.000\ttrn_loss: 0.079\ttrn_char_acc: 0.996\ttrn_word_acc: 0.980\tval_loss: 0.188\tval_char_acc: 0.953\tval_word_acc: 0.836\t(921.99s - 724.42s remaining)\n",
            "\n",
            "Pred: `heavy` :: Truth: `heavy`\n",
            "Pred: `along` :: Truth: `along`\n",
            "Pred: `loss` :: Truth: `loss`\n",
            "Pred: `law` :: Truth: `law`\n",
            "Pred: `wst` :: Truth: `just`\n",
            "\n",
            "EPOCH: 29.000\ttrn_loss: 0.083\ttrn_char_acc: 0.996\ttrn_word_acc: 0.980\tval_loss: 0.175\tval_char_acc: 0.955\tval_word_acc: 0.845\t(954.07s - 690.88s remaining)\n",
            "\n",
            "Pred: `wall` :: Truth: `wall`\n",
            "Pred: `capital` :: Truth: `capital`\n",
            "Pred: `method` :: Truth: `method`\n",
            "Pred: `stratiagy` :: Truth: `strategy`\n",
            "Pred: `moden` :: Truth: `modern`\n",
            "\n",
            "EPOCH: 30.000\ttrn_loss: 0.075\ttrn_char_acc: 0.997\ttrn_word_acc: 0.982\tval_loss: 0.182\tval_char_acc: 0.955\tval_word_acc: 0.835\t(986.04s - 657.36s remaining)\n",
            "\n",
            "Pred: `national` :: Truth: `national`\n",
            "Pred: `campaign` :: Truth: `campaign`\n",
            "Pred: `school` :: Truth: `school`\n",
            "Pred: `deacly` :: Truth: `clearly`\n",
            "Pred: `imagine` :: Truth: `imagine`\n",
            "\n",
            "EPOCH: 31.000\ttrn_loss: 0.079\ttrn_char_acc: 0.997\ttrn_word_acc: 0.983\tval_loss: 0.183\tval_char_acc: 0.956\tval_word_acc: 0.840\t(1018.02s - 623.95s remaining)\n",
            "\n",
            "Pred: `pretty` :: Truth: `pretty`\n",
            "Pred: `until` :: Truth: `until`\n",
            "Pred: `plan` :: Truth: `plan`\n",
            "Pred: `attack` :: Truth: `attack`\n",
            "Pred: `plan` :: Truth: `plan`\n",
            "\n",
            "EPOCH: 32.000\ttrn_loss: 0.069\ttrn_char_acc: 0.997\ttrn_word_acc: 0.986\tval_loss: 0.173\tval_char_acc: 0.957\tval_word_acc: 0.845\t(1050.00s - 590.62s remaining)\n",
            "\n",
            "Pred: `imporlitant` :: Truth: `important`\n",
            "Pred: `establish` :: Truth: `establish`\n",
            "Pred: `certain` :: Truth: `certain`\n",
            "Pred: `lot` :: Truth: `lot`\n",
            "Pred: `it` :: Truth: `it`\n",
            "\n",
            "EPOCH: 33.000\ttrn_loss: 0.067\ttrn_char_acc: 0.997\ttrn_word_acc: 0.985\tval_loss: 0.171\tval_char_acc: 0.958\tval_word_acc: 0.853\t(1082.03s - 557.41s remaining)\n",
            "\n",
            "Pred: `strong` :: Truth: `strong`\n",
            "Pred: `apply` :: Truth: `apply`\n",
            "Pred: `hotel` :: Truth: `hotel`\n",
            "Pred: `hluge` :: Truth: `huge`\n",
            "Pred: `afect` :: Truth: `affect`\n",
            "\n",
            "EPOCH: 34.000\ttrn_loss: 0.066\ttrn_char_acc: 0.998\ttrn_word_acc: 0.988\tval_loss: 0.172\tval_char_acc: 0.956\tval_word_acc: 0.846\t(1114.13s - 524.30s remaining)\n",
            "\n",
            "Pred: `local` :: Truth: `local`\n",
            "Pred: `page` :: Truth: `page`\n",
            "Pred: `agreement` :: Truth: `agreement`\n",
            "Pred: `line` :: Truth: `line`\n",
            "Pred: `ask` :: Truth: `ask`\n",
            "\n",
            "EPOCH: 35.000\ttrn_loss: 0.064\ttrn_char_acc: 0.998\ttrn_word_acc: 0.988\tval_loss: 0.188\tval_char_acc: 0.956\tval_word_acc: 0.843\t(1146.25s - 491.25s remaining)\n",
            "\n",
            "Pred: `debate` :: Truth: `debate`\n",
            "Pred: `plone` :: Truth: `phone`\n",
            "Pred: `huge` :: Truth: `huge`\n",
            "Pred: `role` :: Truth: `role`\n",
            "Pred: `check` :: Truth: `check`\n",
            "\n",
            "EPOCH: 36.000\ttrn_loss: 0.063\ttrn_char_acc: 0.998\ttrn_word_acc: 0.988\tval_loss: 0.166\tval_char_acc: 0.958\tval_word_acc: 0.850\t(1178.41s - 458.27s remaining)\n",
            "\n",
            "Pred: `science` :: Truth: `science`\n",
            "Pred: `naolue` :: Truth: `realize`\n",
            "Pred: `mother` :: Truth: `mother`\n",
            "Pred: `onto` :: Truth: `onto`\n",
            "Pred: `standerd` :: Truth: `standard`\n",
            "\n",
            "EPOCH: 37.000\ttrn_loss: 0.060\ttrn_char_acc: 0.998\ttrn_word_acc: 0.989\tval_loss: 0.164\tval_char_acc: 0.958\tval_word_acc: 0.853\t(1210.56s - 425.33s remaining)\n",
            "\n",
            "Pred: `form` :: Truth: `form`\n",
            "Pred: `management` :: Truth: `management`\n",
            "Pred: `focus` :: Truth: `focus`\n",
            "Pred: `security` :: Truth: `security`\n",
            "Pred: `girl` :: Truth: `goal`\n",
            "\n",
            "EPOCH: 38.000\ttrn_loss: 0.056\ttrn_char_acc: 0.999\ttrn_word_acc: 0.991\tval_loss: 0.164\tval_char_acc: 0.959\tval_word_acc: 0.856\t(1242.82s - 392.47s remaining)\n",
            "\n",
            "Pred: `cuch` :: Truth: `such`\n",
            "Pred: `increase` :: Truth: `increase`\n",
            "Pred: `big` :: Truth: `big`\n",
            "Pred: `indeer` :: Truth: `indeed`\n",
            "Pred: `their` :: Truth: `their`\n",
            "\n",
            "EPOCH: 39.000\ttrn_loss: 0.057\ttrn_char_acc: 0.999\ttrn_word_acc: 0.991\tval_loss: 0.167\tval_char_acc: 0.959\tval_word_acc: 0.855\t(1275.05s - 359.63s remaining)\n",
            "\n",
            "Pred: `attention` :: Truth: `attention`\n",
            "Pred: `law` :: Truth: `law`\n",
            "Pred: `blood` :: Truth: `blood`\n",
            "Pred: `simply` :: Truth: `simply`\n",
            "Pred: `find` :: Truth: `find`\n",
            "\n",
            "EPOCH: 40.000\ttrn_loss: 0.052\ttrn_char_acc: 0.999\ttrn_word_acc: 0.992\tval_loss: 0.166\tval_char_acc: 0.959\tval_word_acc: 0.860\t(1307.23s - 326.81s remaining)\n",
            "\n",
            "Pred: `result` :: Truth: `result`\n",
            "Pred: `mission` :: Truth: `mission`\n",
            "Pred: `authority` :: Truth: `authority`\n",
            "Pred: `lawyer` :: Truth: `lawyer`\n",
            "Pred: `interest` :: Truth: `interest`\n",
            "\n",
            "EPOCH: 41.000\ttrn_loss: 0.057\ttrn_char_acc: 0.998\ttrn_word_acc: 0.990\tval_loss: 0.170\tval_char_acc: 0.959\tval_word_acc: 0.862\t(1339.29s - 293.99s remaining)\n",
            "\n",
            "Pred: `can` :: Truth: `can`\n",
            "Pred: `forward` :: Truth: `forward`\n",
            "Pred: `camera` :: Truth: `camera`\n",
            "Pred: `pretty` :: Truth: `pretty`\n",
            "Pred: `collection` :: Truth: `collection`\n",
            "\n",
            "EPOCH: 42.000\ttrn_loss: 0.052\ttrn_char_acc: 0.999\ttrn_word_acc: 0.992\tval_loss: 0.174\tval_char_acc: 0.959\tval_word_acc: 0.856\t(1371.56s - 261.25s remaining)\n",
            "\n",
            "Pred: `mission` :: Truth: `mission`\n",
            "Pred: `relationstip` :: Truth: `relationship`\n",
            "Pred: `at` :: Truth: `at`\n",
            "Pred: `adult` :: Truth: `adult`\n",
            "Pred: `property` :: Truth: `property`\n",
            "\n",
            "EPOCH: 43.000\ttrn_loss: 0.055\ttrn_char_acc: 0.999\ttrn_word_acc: 0.992\tval_loss: 0.164\tval_char_acc: 0.960\tval_word_acc: 0.856\t(1403.68s - 228.51s remaining)\n",
            "\n",
            "Pred: `article` :: Truth: `article`\n",
            "Pred: `appear` :: Truth: `appear`\n",
            "Pred: `also` :: Truth: `also`\n",
            "Pred: `beat` :: Truth: `beat`\n",
            "Pred: `expect` :: Truth: `expect`\n",
            "\n",
            "EPOCH: 44.000\ttrn_loss: 0.048\ttrn_char_acc: 0.999\ttrn_word_acc: 0.993\tval_loss: 0.164\tval_char_acc: 0.961\tval_word_acc: 0.864\t(1435.79s - 195.79s remaining)\n",
            "\n",
            "Pred: `successful` :: Truth: `successful`\n",
            "Pred: `oushide` :: Truth: `outside`\n",
            "Pred: `identify` :: Truth: `identify`\n",
            "Pred: `indicate` :: Truth: `indicate`\n",
            "Pred: `usually` :: Truth: `usually`\n",
            "\n",
            "EPOCH: 45.000\ttrn_loss: 0.046\ttrn_char_acc: 0.999\ttrn_word_acc: 0.994\tval_loss: 0.192\tval_char_acc: 0.957\tval_word_acc: 0.849\t(1467.94s - 163.10s remaining)\n",
            "\n",
            "Pred: `though` :: Truth: `though`\n",
            "Pred: `blue` :: Truth: `blue`\n",
            "Pred: `country` :: Truth: `country`\n",
            "Pred: `produce` :: Truth: `produce`\n",
            "Pred: `reseut` :: Truth: `result`\n",
            "\n",
            "EPOCH: 46.000\ttrn_loss: 0.050\ttrn_char_acc: 0.999\ttrn_word_acc: 0.993\tval_loss: 0.172\tval_char_acc: 0.959\tval_word_acc: 0.858\t(1500.16s - 130.45s remaining)\n",
            "\n",
            "Pred: `such` :: Truth: `such`\n",
            "Pred: `director` :: Truth: `director`\n",
            "Pred: `land` :: Truth: `land`\n",
            "Pred: `some` :: Truth: `some`\n",
            "Pred: `civil` :: Truth: `civil`\n",
            "\n",
            "EPOCH: 47.000\ttrn_loss: 0.045\ttrn_char_acc: 0.999\ttrn_word_acc: 0.994\tval_loss: 0.160\tval_char_acc: 0.961\tval_word_acc: 0.865\t(1532.37s - 97.81s remaining)\n",
            "\n",
            "Pred: `wife` :: Truth: `wife`\n",
            "Pred: `environmental` :: Truth: `environmental`\n",
            "Pred: `opportunity` :: Truth: `opportunity`\n",
            "Pred: `movie` :: Truth: `movie`\n",
            "Pred: `identify` :: Truth: `identify`\n",
            "\n",
            "EPOCH: 48.000\ttrn_loss: 0.045\ttrn_char_acc: 0.999\ttrn_word_acc: 0.993\tval_loss: 0.182\tval_char_acc: 0.958\tval_word_acc: 0.851\t(1564.78s - 65.20s remaining)\n",
            "\n",
            "Pred: `help` :: Truth: `help`\n",
            "Pred: `brother` :: Truth: `brother`\n",
            "Pred: `run` :: Truth: `run`\n",
            "Pred: `accept` :: Truth: `accept`\n",
            "Pred: `mouth` :: Truth: `mouth`\n",
            "\n",
            "EPOCH: 49.000\ttrn_loss: 0.049\ttrn_char_acc: 0.999\ttrn_word_acc: 0.994\tval_loss: 0.165\tval_char_acc: 0.961\tval_word_acc: 0.861\t(1597.20s - 32.60s remaining)\n",
            "\n",
            "Pred: `catch` :: Truth: `catch`\n",
            "Pred: `deep` :: Truth: `deep`\n",
            "Pred: `I` :: Truth: `I`\n",
            "Pred: `lawyer` :: Truth: `lawyer`\n",
            "Pred: `both` :: Truth: `both`\n",
            "\n",
            "EPOCH: 50.000\ttrn_loss: 0.048\ttrn_char_acc: 0.999\ttrn_word_acc: 0.994\tval_loss: 0.168\tval_char_acc: 0.960\tval_word_acc: 0.863\t(1629.53s - 0.00s remaining)\n",
            "\n",
            "Pred: `nor` :: Truth: `nor`\n",
            "Pred: `esrcialy` :: Truth: `especially`\n",
            "Pred: `born` :: Truth: `born`\n",
            "Pred: `few` :: Truth: `few`\n",
            "Pred: `western` :: Truth: `western`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDpczoK0lvcu",
        "outputId": "53643876-8d7c-4aa0-ecdc-700387322bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "log.plot_epochs(['trn_word_acc','val_word_acc'], title='Training and validation word accuracy')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'log' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-def6761ff7b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trn_word_acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_word_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training and validation word accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'log' is not defined"
          ]
        }
      ]
    }
  ]
}